{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eac39fb",
   "metadata": {},
   "source": [
    "# This notebook generates molecular crystal graph from pickled data from `cif2cluster_data.ipynb` descriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10e9df4-9eea-4387-9526-c70cab161e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import rdkit, rdkit.Chem, rdkit.Chem.rdDepictor, rdkit.Chem.Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f288e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'acetam_GNN_DATA.pkl'\n",
    "file = open(f,'rb')\n",
    "#trajs = pickle.load(file)\n",
    "acetam_trajs = pd.read_pickle(file)\n",
    "# label_str = list(set([k.split(\"-\")[0] for k in trajs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc253dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'glutam_GNN_DATA.pkl'\n",
    "file = open(f,'rb')\n",
    "#trajs = pickle.load(file)\n",
    "glutam_trajs = pd.read_pickle(file)\n",
    "# label_str = list(set([k.split(\"-\")[0] for k in trajs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a4b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'meoh_GNN_DATA.pkl'\n",
    "file = open(f,'rb')\n",
    "#trajs = pickle.load(file)\n",
    "meoh_trajs = pd.read_pickle(file)\n",
    "# label_str = list(set([k.split(\"-\")[0] for k in trajs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a8f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'csd_GNN_DATA.pkl'\n",
    "file = open(f,'rb')\n",
    "#trajs = pickle.load(file)\n",
    "csd_trajs = pd.read_pickle(file)\n",
    "# label_str = list(set([k.split(\"-\")[0] for k in trajs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1bae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = 'GNN_DATA.pkl'\n",
    "#file = open(f,'rb')\n",
    "#trajs = pickle.load(file)\n",
    "#trajs = pd.read_pickle(file)\n",
    "# label_str = list(set([k.split(\"-\")[0] for k in trajs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a96d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now build dataset\n",
    "def generator():\n",
    "    for index,row in acetam_trajs.iterrows():\n",
    "        label = row['Label']\n",
    "        traj = row['Coordinates']\n",
    "        nodes = row['Descriptors']\n",
    "        #for i in range(traj.shape[0]):\n",
    "        yield traj, label, nodes\n",
    "\n",
    "data = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(None, 24), dtype=tf.float32),\n",
    "    ),\n",
    ").shuffle(\n",
    "    1000,\n",
    "    reshuffle_each_iteration=False,  # do not change order each time (!) otherwise will contaminate\n",
    ")\n",
    "\n",
    "# # The shuffling above is really important because this dataset is in order of labels!\n",
    "\n",
    "# val_data = data.take(100)\n",
    "# test_data = data.skip(100).take(100)\n",
    "# train_data = data.skip(200)\n",
    "\n",
    "val_data = data.take(100)\n",
    "test_data = data.skip(100).take(100)\n",
    "train_data = data.skip(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c626a-42d3-4e46-91dd-854215d265dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize 2D projection of 3D data\n",
    "\"\"\"\n",
    "fig, axs = plt.subplots(1, 5, figsize=(12, 2))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# get a few example and plot them\n",
    "for i, (x, y, z) in enumerate(val_data):\n",
    "    # print(x[:,0])\n",
    "    # print(z)\n",
    "    # print(x)\n",
    "    if i == 20:\n",
    "        break\n",
    "    axs[i].plot(x[:, 1], x[:, 2], \".\")\n",
    "    axs[i].set_title(str(i))\n",
    "    axs[i].axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390dde3-8bb3-472d-911f-314e6c01754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this decorator speeds up the function by \"compiling\" it (tracing it)\n",
    "# to run efficienty\n",
    "@tf.function(\n",
    "    reduce_retracing=True,\n",
    ")\n",
    "def get_edges(positions, NN, sorted=True):\n",
    "    M = tf.shape(input=positions)[0]\n",
    "    # adjust NN\n",
    "    NN = tf.minimum(NN, M)\n",
    "    qexpand = tf.expand_dims(positions, 1)  # one column\n",
    "    qTexpand = tf.expand_dims(positions, 0)  # one row\n",
    "    # repeat it to make matrix of all positions\n",
    "    qtile = tf.tile(qexpand, [1, M, 1])\n",
    "    qTtile = tf.tile(qTexpand, [M, 1, 1])\n",
    "    # subtract them to get distance matrix\n",
    "    dist_mat = qTtile - qtile\n",
    "    # mask distance matrix to remove zros (self-interactions)\n",
    "    dist = tf.norm(tensor=dist_mat, axis=2)\n",
    "    mask = dist >= 5e-4\n",
    "    mask_cast = tf.cast(mask, dtype=dist.dtype)\n",
    "    # make masked things be really far\n",
    "    dist_mat_r = dist * mask_cast + (1 - mask_cast) * 1000\n",
    "    topk = tf.math.top_k(-dist_mat_r, k=NN, sorted=sorted)\n",
    "    return -topk.values, topk.indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d9b85-6979-440d-872b-368a6d0dcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import collections\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(12, 2))\n",
    "axs = axs.flatten()\n",
    "for i, (x, y, z) in enumerate(data):\n",
    "    if i == 6:\n",
    "        break\n",
    "    e_f, e_i = get_edges(x, 6)\n",
    "\n",
    "    # make things easier for plotting\n",
    "    e_i = e_i.numpy()\n",
    "    x = x.numpy()\n",
    "    y = y.numpy()\n",
    "\n",
    "    # make lines from origin to its neigbhors\n",
    "    lines = []\n",
    "    colors = []\n",
    "    for j in range(0, x.shape[0], 23):\n",
    "        # lines are [(xstart, ystart), (xend, yend)]\n",
    "        lines.extend([[(x[j, 0], x[j, 1]), (x[k, 0], x[k, 1])] for k in e_i[j]])\n",
    "        colors.extend([f\"C{j}\"] * len(e_i[j]))\n",
    "    lc = collections.LineCollection(lines, linewidths=2, colors=colors)\n",
    "    axs[i].add_collection(lc)\n",
    "    axs[i].plot(x[:, 0], x[:, 1], \".\")\n",
    "    axs[i].axis(\"off\")\n",
    "    #axs[i].set_title(label_str[y])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d78276-3309-4885-8889-6cba94398a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEGREE = 12\n",
    "EDGE_FEATURES = 8\n",
    "MAX_R = 15\n",
    "\n",
    "gamma = 1\n",
    "mu = np.linspace(0, MAX_R, EDGE_FEATURES)\n",
    "\n",
    "\n",
    "def rbf(r):\n",
    "    return tf.exp(-gamma * (r[..., tf.newaxis] - mu) ** 2)\n",
    "\n",
    "\n",
    "def make_graph(x, y, n):\n",
    "    edge_r, edge_i = get_edges(x, MAX_DEGREE)\n",
    "    edge_features = rbf(edge_r)    \n",
    "    return (n, edge_features, edge_i), y[None]\n",
    "\n",
    "\n",
    "graph_train_data = train_data.map(make_graph)\n",
    "graph_val_data = val_data.map(make_graph)\n",
    "graph_test_data = test_data.map(make_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d713f2c-c46f-48f4-960f-a16198984110",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n, e, nn), y in graph_train_data:\n",
    "    print(\"first node:\", n[1].numpy())\n",
    "    print(\"first node, first edge features:\", e[1, 1].numpy())\n",
    "    print(\"first node, all neighbors\", nn[1].numpy())\n",
    "    print(\"label\", y.numpy())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71820fb2-9ae4-485a-80c3-7eca4c9d964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssp(x):\n",
    "    # shifted softplus activation\n",
    "    return tf.math.log(0.5 * tf.math.exp(x) + 0.5)\n",
    "\n",
    "\n",
    "def make_h1(units):\n",
    "    return tf.keras.Sequential([tf.keras.layers.Dense(units)])\n",
    "\n",
    "\n",
    "def make_h2(units):\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(units, activation=ssp),\n",
    "            tf.keras.layers.Dense(units, activation=ssp),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def make_h3(units):\n",
    "    return tf.keras.Sequential(\n",
    "        [tf.keras.layers.Dense(units, activation=ssp), tf.keras.layers.Dense(units)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706402c8-6e96-40f2-9ced-3ded06c9f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchNetModel(tf.keras.Model):\n",
    "    \"\"\"Implementation of SchNet Model\"\"\"\n",
    "\n",
    "    def __init__(self, gnn_blocks, channels, label_dim, **kwargs):\n",
    "        super(SchNetModel, self).__init__(**kwargs)\n",
    "        self.gnn_blocks = gnn_blocks\n",
    "\n",
    "        # build our layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(89, channels-24 + 1)\n",
    "        self.h1s = [make_h1(channels) for _ in range(self.gnn_blocks)]\n",
    "        self.h2s = [make_h2(channels) for _ in range(self.gnn_blocks)]\n",
    "        self.h3s = [make_h3(channels) for _ in range(self.gnn_blocks)]\n",
    "        self.readout_l1 = tf.keras.layers.Dense(channels // 2, activation=ssp)\n",
    "        self.readout_l2 = tf.keras.layers.Dense(label_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        nodes, edge_features, edge_i = inputs\n",
    "        #print(nodes.shape,edge_features.shape,edge_i.shape)\n",
    "        # turn node types as index to features\n",
    "        # embedded = self.embedding(nodes[:,0])\n",
    "        nodes = tf.concat([self.embedding(nodes[:,0]),nodes[:,1:]],1)\n",
    "        print(nodes.shape,edge_features.shape,edge_i.shape)\n",
    "        for i in range(self.gnn_blocks):\n",
    "            # get the node features per edge\n",
    "            v_sk = tf.gather(nodes, edge_i)\n",
    "            e_k = self.h1s[i](v_sk) * self.h2s[i](edge_features)\n",
    "            e_i = tf.reduce_sum(e_k, axis=1)\n",
    "            nodes += self.h3s[i](e_i)\n",
    "        # readout now\n",
    "        nodes = self.readout_l1(nodes)\n",
    "        nodes = self.readout_l2(nodes)\n",
    "        return tf.reduce_mean(nodes, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da03cc-e8dc-40fd-9553-dd7133b23db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_schnet = SchNetModel(3, 32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c5123-3893-4048-a90a-ecf65695e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in graph_test_data:\n",
    "    #print(x[0])\n",
    "    yhat = small_schnet(x)\n",
    "    #break\n",
    "    print(yhat.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8fa16-93b0-4f35-b78b-503060c5d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b8749-fb13-4833-b4c6-7db04304f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed(nodes[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef178a-a792-464f-9839-55be95429923",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "BMS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
